
input_queries: "queries.csv"  # file with a list of queries to use for evaluation

# Evaluation results are written to the "results_folder" folder.
# You can override the names of files in this folder by specifying 'generated_answers', 'eval_results_file', and 'metrics_file'.
results_folder: "results/"
generated_answers: "answers.csv"
eval_results_file: "results.csv"
metrics_file: "metrics.png"

evaluator:
  type: "TRECEvaluator"  
  model:
    type: "OpenAIModel"
    name: "gpt-4o-mini"
    api_key: ${oc.env:OPENAI_API_KEY}  # Reads from environment variable.

connector:
  type: "LangChainConnector"  
  options:
    # the folder with the files to be indexed into LlamaIndex
    # all files in this folder and any subfolders will be indexed
    folder: /path/to/folder-with-files/   
    top_k: 10
    max_workers: -1  # -1 to use all available CPU cores for parallel processing.
    repeat_query: 5 # set this more than one to repeat the query multiple times for consistency evaluation
